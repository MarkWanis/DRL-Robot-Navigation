This document outlines the progress of the **DRL Robot Navigation with ROS2** project by Mark Wanis and Jaran Mann (Fall 2025). The project focuses on training and implementing a **deep reinforcement learning (DRL)** model for autonomous TurtleBot navigation using **ROS2** and **Gazebo**. Early work involved gaining familiarity with robot inputs (LIDAR, odometry, IMU, position, velocity, and heading) and outputs (linear and angular velocity), as well as recording and graphing sensor data to analyze response times. The team transitioned from using odometry to encoder and JointState data for more accurate velocity measurements, visualized using Python’s **pandas** and **matplotlib**. Subsequent efforts focused on installing and running **Gazebo Fortress** on Ubuntu, troubleshooting ROS key and GitHub setup issues, and learning Gazebo’s simulation fundamentals through the TurtleBot3 eManual. After resolving environment and dependency conflicts, the team successfully ran TurtleBot simulations and began applying a **trained DRL policy** from a previous research project to both the virtual and physical robots. Current goals include understanding the simulation’s input-output structure, replicating the reinforcement learning pipeline, and deploying the trained model for real-world TurtleBot navigation.
